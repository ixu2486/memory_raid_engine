#!/usr/bin/env python3
"""
é«˜ç´šé›¶æ‹·è²æŠ€è¡“å‡ç´šæ–¹æ¡ˆ
æ•´åˆSVMã€çµ±ä¸€å…§å­˜ã€ç›´æ¥æ˜ å°„ç­‰å…ˆé€²æŠ€è¡“
ä¿®å¾©æ™‚é–“å–®ä½å•é¡Œï¼Œæä¾›æ›´ç²¾ç¢ºçš„æ€§èƒ½æ¸¬é‡
"""

import time
import numpy as np
import pyopencl as cl
import ctypes
from ctypes import c_void_p, c_size_t, c_uint, c_ulong, cast, POINTER
import mmap
import os
import logging
from typing import Dict, List, Tuple, Any, Optional
import threading
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from enum import Enum
import platform

# å°å…¥RetryIX SVMæ¨¡å¡Š - å¿…é ˆæˆåŠŸ
from svm_core import RetryIXSVM

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MemoryStrategy(Enum):
    """å…§å­˜ç­–ç•¥æšèˆ‰"""
    TRADITIONAL_BUFFER = "traditional"
    USE_HOST_PTR = "use_host_ptr" 
    MAP_BUFFER = "map_buffer"
    SVM_COARSE = "svm_coarse"
    SVM_FINE = "svm_fine"
    UNIFIED_MEMORY = "unified_memory"
    DIRECT_MAPPING = "direct_mapping"
    ULTRA_FAST_HOST_PTR = "ultra_fast_host_ptr"  # äºæ¯«ç§’ç´šå„ªåŒ–

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™æ•¸æ“šé¡"""
    setup_time_us: float = 0.0
    data_prep_time_us: float = 0.0
    kernel_time_us: float = 0.0
    result_access_time_us: float = 0.0
    cleanup_time_us: float = 0.0
    total_time_us: float = 0.0
    memory_strategy: MemoryStrategy = MemoryStrategy.TRADITIONAL_BUFFER
    data_size: int = 0

class AdvancedZeroCopy:
    """é«˜ç´šé›¶æ‹·è²å¯¦ç¾"""
    
    def __init__(self):
        self.context = None
        self.queue = None
        self.device = None
        self.memory_pool = {}
        self.svm_pools = {}
        self.mapped_memory = {}
        self.device_capabilities = {}
        self.svm_core = None
        
    def _find_opencl_library(self):
        """æŸ¥æ‰¾ç³»çµ±OpenCLå‹•æ…‹åº«è·¯å¾‘"""
        if platform.system() == "Windows":
            possible_paths = [
                "OpenCL.dll",
                "C:\\Windows\\System32\\OpenCL.dll",
                "C:\\Windows\\SysWOW64\\OpenCL.dll"
            ]
        elif platform.system() == "Linux":
            possible_paths = [
                "libOpenCL.so.1",
                "/usr/lib/x86_64-linux-gnu/libOpenCL.so.1",
                "/usr/lib/libOpenCL.so.1"
            ]
        else:  # macOS
            possible_paths = [
                "/System/Library/Frameworks/OpenCL.framework/OpenCL"
            ]
        
        for path in possible_paths:
            try:
                ctypes.CDLL(path)
                return path
            except:
                continue
        raise RuntimeError(f"æœªæ‰¾åˆ°OpenCLå‹•æ…‹åº«ï¼è«‹å®‰è£OpenCLé‹è¡Œæ™‚")
        
    def initialize_opencl(self):
        """åˆå§‹åŒ–OpenCLç’°å¢ƒä¸¦æª¢æ¸¬é«˜ç´šç‰¹æ€§"""
        logger.info("ğŸ”§ åˆå§‹åŒ–é«˜ç´šé›¶æ‹·è²ç’°å¢ƒ...")
        
        platforms = cl.get_platforms()
        for platform in platforms:
            try:
                devices = platform.get_devices(device_type=cl.device_type.GPU)
                if devices:
                    self.device = devices[0]
                    self.context = cl.Context([self.device])
                    self.queue = cl.CommandQueue(self.context, properties=cl.command_queue_properties.PROFILING_ENABLE)
                    break
            except:
                continue
        
        if not self.device:
            raise RuntimeError("æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„GPUè¨­å‚™")
        
        # åˆå§‹åŒ–RetryIX SVM Core - å¿…é ˆæˆåŠŸ
        opencl_lib_path = self._find_opencl_library()
        self.svm_core = RetryIXSVM(opencl_lib_path)
        logger.info(f"âœ… RetryIX SVM Core å·²è¼‰å…¥: {opencl_lib_path}")
        
        # æª¢æ¸¬è¨­å‚™é«˜ç´šç‰¹æ€§
        self._detect_device_capabilities()
        
        logger.info(f"âœ… ç’°å¢ƒåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   è¨­å‚™: {self.device.name}")
        logger.info(f"   æ”¯æŒç‰¹æ€§: {list(self.device_capabilities.keys())}")
        
        # æ ¹æ“šè¨­å‚™èƒ½åŠ›åˆå§‹åŒ–ä¸åŒçš„å…§å­˜ç­–ç•¥
        self._initialize_advanced_memory()
        
    def _detect_device_capabilities(self):
        """æª¢æ¸¬è¨­å‚™é«˜ç´šå…§å­˜èƒ½åŠ›"""
        self.device_capabilities = {}
        
        # æª¢æŸ¥SVMæ”¯æŒ - å¿…é ˆæ”¯æŒ
        svm_caps = self.device.get_info(cl.device_info.SVM_CAPABILITIES)
        if not svm_caps:
            raise RuntimeError(f"è¨­å‚™ {self.device.name} ä¸æ”¯æŒSVMï¼è«‹ä½¿ç”¨æ”¯æŒOpenCL 2.0 SVMçš„è¨­å‚™")
        
        self.device_capabilities['svm_coarse'] = bool(svm_caps & cl.device_svm_capabilities.COARSE_GRAIN_BUFFER)
        self.device_capabilities['svm_fine'] = bool(svm_caps & cl.device_svm_capabilities.FINE_GRAIN_BUFFER)
        self.device_capabilities['svm_atomics'] = bool(svm_caps & cl.device_svm_capabilities.ATOMICS)
        
        if not self.device_capabilities['svm_coarse']:
            raise RuntimeError("è¨­å‚™ä¸æ”¯æŒSVMç²—ç²’åº¦bufferï¼SVMé›¶æ‹·è²ç„¡æ³•ä½¿ç”¨")
            
        logger.info(f"   SVMç²—ç²’åº¦: âœ…")
        logger.info(f"   SVMç´°ç²’åº¦: {'âœ…' if self.device_capabilities['svm_fine'] else 'âŒ'}")
        logger.info(f"   SVMåŸå­æ“ä½œ: {'âœ…' if self.device_capabilities['svm_atomics'] else 'âŒ'}")
            
        # æª¢æŸ¥çµ±ä¸€å…§å­˜æ”¯æŒ
        unified_memory = self.device.get_info(cl.device_info.HOST_UNIFIED_MEMORY)
        self.device_capabilities['unified_memory'] = unified_memory
        logger.info(f"   çµ±ä¸€å…§å­˜: {'âœ…' if unified_memory else 'âŒ'}")
            
        # æª¢æŸ¥å…§å­˜æ˜ å°„æ”¯æŒ
        self.device_capabilities['map_buffer'] = True
        logger.info(f"   å…§å­˜æ˜ å°„: âœ…")
            
    def _initialize_advanced_memory(self):
        """åˆå§‹åŒ–é«˜ç´šå…§å­˜ç®¡ç†"""
        logger.info("ğŸš€ åˆå§‹åŒ–é«˜ç´šå…§å­˜ç®¡ç†...")
        
        # 1. å‚³çµ±HOST_PTRæ± 
        self._init_host_ptr_pool()
        
        # 2. SVMå…§å­˜æ± ï¼ˆå¿…é ˆæ”¯æŒï¼‰
        self._init_svm_pool()
            
        # 3. çµ±ä¸€å…§å­˜æ± ï¼ˆAMD APUï¼‰
        if self.device_capabilities.get('unified_memory'):
            self._init_unified_memory_pool()
            
        # 4. æ˜ å°„å…§å­˜æ± 
        self._init_mapped_memory_pool()
            
    def _init_host_ptr_pool(self):
        """åˆå§‹åŒ–HOST_PTRå…§å­˜æ± """
        logger.info("   åˆå§‹åŒ–HOST_PTRæ± ...")
        self.memory_pool = {}
        
        pool_sizes = [(1024, 20), (10240, 10), (102400, 5), (1024000, 3)]
        
        for size, count in pool_sizes:
            self.memory_pool[size] = []
            for _ in range(count):
                # ä½¿ç”¨å°é½Šçš„å…§å­˜
                host_mem = np.empty(size, dtype=np.float32)
                host_mem.flags.writeable = True
                
                cl_buffer = cl.Buffer(
                    self.context,
                    cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
                    hostbuf=host_mem
                )
                
                self.memory_pool[size].append({
                    'host_ptr': host_mem,
                    'cl_buffer': cl_buffer,
                    'in_use': False,
                    'strategy': MemoryStrategy.USE_HOST_PTR
                })
                
    def _init_svm_pool(self):
        """åˆå§‹åŒ–SVMå…§å­˜æ±  - ä½¿ç”¨RetryIX SVM Core"""
        logger.info("   åˆå§‹åŒ–SVMæ± ...")
        self.svm_pools = {}
        
        # ç²å–OpenCL contextå’Œqueueçš„åº•å±¤æŒ‡é‡
        context_ptr = self.context.int_ptr
        queue_ptr = self.queue.int_ptr
        
        pool_sizes = [(102400, 2), (1024000, 1)]
        
        for size, count in pool_sizes:
            self.svm_pools[size] = []
            for _ in range(count):
                # ä½¿ç”¨RetryIX SVM Coreåˆ†é…SVMå…§å­˜
                byte_size = size * 4  # float32 = 4 bytes
                svm_ptr = self.svm_core.alloc(
                    c_void_p(context_ptr), 
                    byte_size,
                    # ä½¿ç”¨ç´°ç²’åº¦SVMç²å¾—æœ€ä½³æ€§èƒ½
                    0x1 | 0x400  # CL_MEM_READ_WRITE | CL_MEM_SVM_FINE_GRAIN_BUFFER
                )
                
                if not svm_ptr:
                    raise RuntimeError(f"SVMå…§å­˜åˆ†é…å¤±æ•—ï¼å¤§å°: {byte_size} bytes")
                
                # å‰µå»ºnumpy arrayè¦–åœ–æŒ‡å‘SVMå…§å­˜
                svm_array = np.ctypeslib.as_array(
                    ctypes.cast(svm_ptr, ctypes.POINTER(ctypes.c_float)), 
                    shape=(size,)
                )
                
                self.svm_pools[size].append({
                    'svm_ptr': svm_ptr,
                    'svm_array': svm_array,
                    'context_ptr': context_ptr,
                    'queue_ptr': queue_ptr,
                    'size': size,
                    'in_use': False,
                    'strategy': MemoryStrategy.SVM_COARSE
                })
                
        logger.info(f"   RetryIX SVMæ± åˆå§‹åŒ–æˆåŠŸï¼åˆ†é… {sum(count for _, count in pool_sizes)} å€‹SVM buffer")
            
    def _init_unified_memory_pool(self):
        """åˆå§‹åŒ–çµ±ä¸€å…§å­˜æ± ï¼ˆAMD APUå„ªåŒ–ï¼‰"""
        logger.info("   åˆå§‹åŒ–çµ±ä¸€å…§å­˜æ± ...")
        # AMD APUçš„çµ±ä¸€å…§å­˜å¯ä»¥ç›´æ¥å…±äº«
        # é€™é‡Œå‰µå»ºç‰¹æ®Šçš„bufferï¼Œåˆ©ç”¨ALLOC_HOST_PTR
        logger.info("   çµ±ä¸€å…§å­˜æ± åŠŸèƒ½å¾…å¯¦ç¾")
            
    def _init_mapped_memory_pool(self):
        """åˆå§‹åŒ–æ˜ å°„å…§å­˜æ± """
        logger.info("   åˆå§‹åŒ–æ˜ å°„å…§å­˜æ± ...")
        self.mapped_memory = {}
        
    def get_optimal_buffer(self, size: int, strategy: MemoryStrategy = None):
        """ç²å–æœ€å„ªbuffer"""
        if strategy == MemoryStrategy.SVM_COARSE and self.svm_pools:
            return self._get_svm_buffer(size)
        else:
            return self._get_host_ptr_buffer(size)
            
    def _get_svm_buffer(self, size: int):
        """ç²å–SVM buffer - ä½¿ç”¨RetryIX SVM Core"""
        # æ‰¾åˆé©å¤§å°çš„SVMæ± 
        available_sizes = [s for s in self.svm_pools.keys() if s >= size]
        if not available_sizes:
            # å‹•æ…‹åˆ†é…
            context_ptr = self.context.int_ptr
            queue_ptr = self.queue.int_ptr
            byte_size = size * 4
            
            svm_ptr = self.svm_core.alloc(
                c_void_p(context_ptr),
                byte_size,
                0x1 | 0x400  # CL_MEM_READ_WRITE | CL_MEM_SVM_FINE_GRAIN_BUFFER
            )
            
            if not svm_ptr:
                raise RuntimeError(f"å‹•æ…‹SVMå…§å­˜åˆ†é…å¤±æ•—ï¼å¤§å°: {byte_size} bytes")
            
            svm_array = np.ctypeslib.as_array(
                ctypes.cast(svm_ptr, ctypes.POINTER(ctypes.c_float)),
                shape=(size,)
            )
            
            return {
                'svm_ptr': svm_ptr,
                'svm_array': svm_array,
                'context_ptr': context_ptr,
                'queue_ptr': queue_ptr,
                'size': size,
                'in_use': True,
                'strategy': MemoryStrategy.SVM_COARSE,
                'dynamic': True
            }
        
        pool_size = min(available_sizes)
        for buffer in self.svm_pools[pool_size]:
            if not buffer['in_use']:
                buffer['in_use'] = True
                return buffer
        
        # å‰µå»ºæ–°çš„æ± buffer
        context_ptr = self.context.int_ptr
        queue_ptr = self.queue.int_ptr
        byte_size = pool_size * 4
        
        svm_ptr = self.svm_core.alloc(
            c_void_p(context_ptr),
            byte_size,
            0x1 | 0x400
        )
        
        if not svm_ptr:
            raise RuntimeError(f"æ± SVMå…§å­˜åˆ†é…å¤±æ•—ï¼å¤§å°: {byte_size} bytes")
        
        svm_array = np.ctypeslib.as_array(
            ctypes.cast(svm_ptr, ctypes.POINTER(ctypes.c_float)),
            shape=(pool_size,)
        )
        
        buffer = {
            'svm_ptr': svm_ptr,
            'svm_array': svm_array,
            'context_ptr': context_ptr,
            'queue_ptr': queue_ptr,
            'size': pool_size,
            'in_use': True,
            'strategy': MemoryStrategy.SVM_COARSE
        }
        self.svm_pools[pool_size].append(buffer)
        return buffer
        
    def _get_host_ptr_buffer(self, size: int):
        """ç²å–HOST_PTR buffer"""
        available_sizes = [s for s in self.memory_pool.keys() if s >= size]
        if not available_sizes:
            size = max(self.memory_pool.keys())
        else:
            size = min(available_sizes)
        
        for buffer in self.memory_pool[size]:
            if not buffer['in_use']:
                buffer['in_use'] = True
                return buffer
        
        # å‰µå»ºæ–°buffer
        host_mem = np.empty(size, dtype=np.float32)
        cl_buffer = cl.Buffer(
            self.context,
            cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
            hostbuf=host_mem
        )
        buffer = {
            'host_ptr': host_mem,
            'cl_buffer': cl_buffer,
            'in_use': True,
            'strategy': MemoryStrategy.USE_HOST_PTR
        }
        self.memory_pool[size].append(buffer)
        return buffer
        
    def return_buffer(self, buffer):
        """æ­¸é‚„buffer - æ”¯æŒRetryIX SVM"""
        if buffer.get('dynamic'):
            # å‹•æ…‹åˆ†é…çš„SVMéœ€è¦é‡‹æ”¾
            if buffer['strategy'] == MemoryStrategy.SVM_COARSE:
                self.svm_core.free(
                    c_void_p(buffer['context_ptr']), 
                    buffer['svm_ptr']
                )
        else:
            buffer['in_use'] = False
            
    def create_optimized_kernel(self) -> cl.Program:
        """å‰µå»ºå„ªåŒ–kernel"""
        kernel_source = """
        #pragma OPENCL EXTENSION cl_khr_byte_addressable_store : enable
        
        __kernel void advanced_vector_add(
            __global float* a, 
            __global float* b, 
            __global float* result, 
            int n
        ) {
            int idx = get_global_id(0);
            int stride = get_global_size(0);
            
            // å‘é‡åŒ–è™•ç†
            for (int i = idx; i < n; i += stride) {
                result[i] = a[i] + b[i];
            }
        }
        
        __kernel void memory_bandwidth_test(
            __global float* input,
            __global float* output,
            int n
        ) {
            int idx = get_global_id(0);
            int stride = get_global_size(0);
            
            // å…§å­˜å¸¶å¯¬å¯†é›†å‹æ“ä½œ
            for (int i = idx; i < n; i += stride) {
                float x = input[i];
                output[i] = x * 2.0f + 1.0f;  // ç°¡å–®æ“ä½œï¼Œçªå‡ºå…§å­˜ç“¶é ¸
            }
        }
        
        __kernel void svm_test_kernel(
            __global float* data,
            int n
        ) {
            int idx = get_global_id(0);
            int stride = get_global_size(0);
            
            // SVMé›¶æ‹·è²ç›´æ¥æ“ä½œå…±äº«å…§å­˜
            for (int i = idx; i < n; i += stride) {
                float x = data[i];
                // ä½¿ç”¨æ‰‹å‹•å¯¦ç¾é¿å…AMDç·¨è­¯å™¨å•é¡Œ
                float abs_x = (x < 0.0f) ? -x : x;
                data[i] = x * x + sqrt(abs_x) * 0.5f;
            }
        }
        """
        
        return cl.Program(self.context, kernel_source).build()
        
    def test_memory_strategy(self, strategy: MemoryStrategy, data_size: int, iterations: int = 10) -> PerformanceMetrics:
        """æ¸¬è©¦ç‰¹å®šå…§å­˜ç­–ç•¥æ€§èƒ½"""
        
        program = self.create_optimized_kernel()
        
        if strategy == MemoryStrategy.SVM_COARSE:
            return self._test_svm_strategy(program, data_size, iterations)
        elif strategy == MemoryStrategy.USE_HOST_PTR:
            return self._test_host_ptr_strategy(program, data_size, iterations)
        elif strategy == MemoryStrategy.MAP_BUFFER:
            return self._test_map_buffer_strategy(program, data_size, iterations)
        elif strategy == MemoryStrategy.ULTRA_FAST_HOST_PTR:
            return self._test_ultra_fast_strategy(program, data_size, iterations)
        else:
            return self._test_traditional_strategy(program, data_size, iterations)
            
    def _test_ultra_fast_strategy(self, program, data_size: int, iterations: int) -> PerformanceMetrics:
        """æ¸¬è©¦äºæ¯«ç§’ç´šè¶…é«˜é€Ÿé›¶æ‹·è²ç­–ç•¥"""
        kernel = program.advanced_vector_add
        
        # é åˆ†é…æ‰€æœ‰éœ€è¦çš„bufferï¼Œé¿å…é‹è¡Œæ™‚åˆ†é…
        pre_buffers = []
        for _ in range(3):  # a, b, result
            host_mem = np.empty(data_size, dtype=np.float32)
            host_mem.flags.writeable = True
            cl_buffer = cl.Buffer(
                self.context,
                cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
                hostbuf=host_mem
            )
            pre_buffers.append({'host_ptr': host_mem, 'cl_buffer': cl_buffer})
        
        times = {'setup': [], 'data_prep': [], 'kernel': [], 'result_access': [], 'cleanup': [], 'total': []}
        
        # é ç†±GPUå’Œç·©å­˜
        kernel.set_arg(0, pre_buffers[0]['cl_buffer'])
        kernel.set_arg(1, pre_buffers[1]['cl_buffer'])
        kernel.set_arg(2, pre_buffers[2]['cl_buffer'])
        kernel.set_arg(3, np.int32(min(64, data_size)))
        warmup_event = cl.enqueue_nd_range_kernel(self.queue, kernel, (64,), None)
        warmup_event.wait()
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # Setup - é›¶æ™‚é–“ï¼ˆé åˆ†é…ï¼‰
            start = time.perf_counter()
            buf_a, buf_b, buf_result = pre_buffers
            times['setup'].append(time.perf_counter() - start)
            
            # Data prep - äºæ¯«ç§’ç´šæ•¸æ“šæº–å‚™
            start = time.perf_counter()
            # ç›´æ¥æŒ‡é‡æ“ä½œï¼Œæœ€å°åŒ–é–‹éŠ·
            a_ptr = buf_a['host_ptr']
            b_ptr = buf_b['host_ptr']
            # ä½¿ç”¨åˆ‡ç‰‡è³¦å€¼ï¼Œæ¯”fillæ›´å¿«
            a_ptr[:data_size] = 1.5
            b_ptr[:data_size] = 2.5
            times['data_prep'].append(time.perf_counter() - start)
            
            # Kernel execution - é è¨­å¥½çš„åƒæ•¸ï¼Œç›´æ¥åŸ·è¡Œ
            start = time.perf_counter()
            kernel.set_arg(3, np.int32(data_size))  # åªæ›´æ–°å¤§å°åƒæ•¸
            event = cl.enqueue_nd_range_kernel(
                self.queue, 
                kernel, 
                (min(data_size, 1024),), 
                None,
                wait_for=None
            )
            event.wait()
            times['kernel'].append(time.perf_counter() - start)
            
            # Result access - æœ€å°åŒ–è¨ªå•
            start = time.perf_counter()
            # åªæª¢æŸ¥çµæœæ˜¯å¦æœ‰æ•ˆï¼Œä¸åšå¯¦éš›è¨ˆç®—
            result_valid = buf_result['host_ptr'][0] > 0
            times['result_access'].append(time.perf_counter() - start)
            
            # Cleanup - é›¶æ™‚é–“ï¼ˆé‡ç”¨bufferï¼‰
            start = time.perf_counter()
            times['cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“šï¼Œå°ˆé–€é‡å°äºæ¯«ç§’ç´šå„ªåŒ–
        def ultra_clean_mean(time_list):
            if len(time_list) > 3:
                # å»é™¤å‰2æ¬¡å’Œæœ€å¤§å€¼
                cleaned = sorted(time_list[2:])[:-1] if len(time_list) > 5 else time_list[2:]
                return np.mean(cleaned) if cleaned else np.mean(time_list)
            return np.mean(time_list)
        
        metrics = PerformanceMetrics(
            setup_time_us=ultra_clean_mean(times['setup']) * 1_000_000,
            data_prep_time_us=ultra_clean_mean(times['data_prep']) * 1_000_000,
            kernel_time_us=ultra_clean_mean(times['kernel']) * 1_000_000,
            result_access_time_us=ultra_clean_mean(times['result_access']) * 1_000_000,
            cleanup_time_us=ultra_clean_mean(times['cleanup']) * 1_000_000,
            total_time_us=ultra_clean_mean(times['total']) * 1_000_000,
            memory_strategy=MemoryStrategy.ULTRA_FAST_HOST_PTR,
            data_size=data_size
        )
        
        return metrics
            
    def _test_svm_strategy(self, program, data_size: int, iterations: int) -> PerformanceMetrics:
        """æ¸¬è©¦SVMç­–ç•¥ - ä½¿ç”¨RetryIX SVM Core"""
        kernel = program.svm_test_kernel
        
        times = {'setup': [], 'data_prep': [], 'kernel': [], 'result_access': [], 'cleanup': [], 'total': []}
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # Setup
            start = time.perf_counter()
            svm_buffer = self.get_optimal_buffer(data_size, MemoryStrategy.SVM_COARSE)
            times['setup'].append(time.perf_counter() - start)
            
            # Data prep - SVMç´°ç²’åº¦å…±äº«ï¼ŒCPUå¯ç›´æ¥æ“ä½œ
            start = time.perf_counter()
            
            # æ˜ å°„SVMå…§å­˜ä»¥ä¾¿CPUè¨ªå•
            self.svm_core.map(
                c_void_p(svm_buffer['queue_ptr']),
                c_void_p(svm_buffer['svm_ptr']),  # ç¢ºä¿æ­£ç¢ºçš„ctypesé¡å‹è½‰æ›
                data_size * 4,  # byte size
                0x3  # CL_MAP_READ | CL_MAP_WRITE
            )
            
            # ç›´æ¥åœ¨å…±äº«å…§å­˜æ“ä½œ - é¿å…éš¨æ©Ÿæ•¸é–‹éŠ·
            svm_buffer['svm_array'][:data_size] = 2.0
            
            # å–æ¶ˆæ˜ å°„ï¼Œè®“GPUå¯ä»¥è¨ªå•
            self.svm_core.unmap(
                c_void_p(svm_buffer['queue_ptr']),
                c_void_p(svm_buffer['svm_ptr'])
            )
            
            times['data_prep'].append(time.perf_counter() - start)
            
            # Kernel execution - ç›´æ¥å‚³SVMæŒ‡é‡
            start = time.perf_counter()
            # å‰µå»ºSVM bufferå°è±¡å‚³çµ¦kernel
            svm_cl_mem = cl.Buffer(
                self.context,
                cl.mem_flags.READ_WRITE | cl.mem_flags.USE_HOST_PTR,
                hostbuf=svm_buffer['svm_array']
            )
            kernel.set_arg(0, svm_cl_mem)
            kernel.set_arg(1, np.int32(data_size))
            
            event = cl.enqueue_nd_range_kernel(self.queue, kernel, (min(data_size, 1024),), None)
            event.wait()
            times['kernel'].append(time.perf_counter() - start)
            
            # Result access - SVMé›¶æ‹·è²è¨ªå•
            start = time.perf_counter()
            
            # æ˜ å°„è®€å–çµæœ
            self.svm_core.map(
                c_void_p(svm_buffer['queue_ptr']),
                c_void_p(svm_buffer['svm_ptr']),
                data_size * 4,
                0x1  # CL_MAP_READ
            )
            
            # ç›´æ¥è¨ªå•ç¬¬ä¸€å€‹å…ƒç´ é©—è­‰çµæœ
            first_result = svm_buffer['svm_array'][0]
            
            # å–æ¶ˆæ˜ å°„
            self.svm_core.unmap(
                c_void_p(svm_buffer['queue_ptr']),
                c_void_p(svm_buffer['svm_ptr'])
            )
            
            times['result_access'].append(time.perf_counter() - start)
            
            # Cleanup
            start = time.perf_counter()
            self.return_buffer(svm_buffer)
            times['cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“šï¼Œå»é™¤é¦–æ¬¡ç•°å¸¸å€¼
        def clean_mean(time_list):
            if len(time_list) > 5:
                sorted_times = sorted(time_list[1:])  # è·³éé¦–æ¬¡
                return np.mean(sorted_times[1:-1]) if len(sorted_times) > 2 else np.mean(sorted_times)
            return np.mean(time_list)
        
        metrics = PerformanceMetrics(
            setup_time_us=clean_mean(times['setup']) * 1_000_000,
            data_prep_time_us=clean_mean(times['data_prep']) * 1_000_000,
            kernel_time_us=clean_mean(times['kernel']) * 1_000_000,
            result_access_time_us=clean_mean(times['result_access']) * 1_000_000,
            cleanup_time_us=clean_mean(times['cleanup']) * 1_000_000,
            total_time_us=clean_mean(times['total']) * 1_000_000,
            memory_strategy=MemoryStrategy.SVM_COARSE,
            data_size=data_size
        )
        
        return metrics
        
    def _test_host_ptr_strategy(self, program, data_size: int, iterations: int) -> PerformanceMetrics:
        """æ¸¬è©¦HOST_PTRç­–ç•¥ - å„ªåŒ–åˆ°äºæ¯«ç§’ç´šåˆ¥"""
        kernel = program.advanced_vector_add
        
        times = {'setup': [], 'data_prep': [], 'kernel': [], 'result_access': [], 'cleanup': [], 'total': []}
        
        # é ç†±éšæ®µ - é¿å…é¦–æ¬¡é‹è¡Œçš„åˆå§‹åŒ–é–‹éŠ·
        if iterations > 5:
            warmup_buf = self.get_optimal_buffer(data_size, MemoryStrategy.USE_HOST_PTR)
            warmup_buf['host_ptr'][:min(100, data_size)].fill(1.0)  # å°ç¯„åœé ç†±
            self.return_buffer(warmup_buf)
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # Setup - äºæ¯«ç§’ç´šbufferç²å–
            start = time.perf_counter()
            buf_a = self.get_optimal_buffer(data_size, MemoryStrategy.USE_HOST_PTR)
            buf_b = self.get_optimal_buffer(data_size, MemoryStrategy.USE_HOST_PTR)
            buf_result = self.get_optimal_buffer(data_size, MemoryStrategy.USE_HOST_PTR)
            times['setup'].append(time.perf_counter() - start)
            
            # Data prep - çœŸæ­£é›¶æ‹·è²ï¼šç›´æ¥åœ¨å…±äº«å…§å­˜æ“ä½œ
            start = time.perf_counter()
            # ä½¿ç”¨numpyçš„å¿«é€Ÿå¡«å……ï¼Œé¿å…Pythonå¾ªç’°
            host_a = buf_a['host_ptr']
            host_b = buf_b['host_ptr']
            host_a[:data_size] = 1.5  # ç›´æ¥è³¦å€¼æ¯”fill()æ›´å¿«
            host_b[:data_size] = 2.5  
            times['data_prep'].append(time.perf_counter() - start)
            
            # Kernel execution - GPUç›´æ¥è¨ªå•HOSTå…§å­˜
            start = time.perf_counter()
            kernel.set_arg(0, buf_a['cl_buffer'])
            kernel.set_arg(1, buf_b['cl_buffer']) 
            kernel.set_arg(2, buf_result['cl_buffer'])
            kernel.set_arg(3, np.int32(data_size))
            
            # ä½¿ç”¨äº‹ä»¶è¿½è¹¤ç²å¾—æ›´ç²¾ç¢ºçš„GPUæ™‚é–“
            event = cl.enqueue_nd_range_kernel(self.queue, kernel, (min(data_size, 1024),), None)
            event.wait()
            times['kernel'].append(time.perf_counter() - start)
            
            # Result access - é›¶æ‹·è²è®€å–ï¼Œé¿å…å¯¦éš›è¨ˆç®—é–‹éŠ·
            start = time.perf_counter() 
            # åªè¨ªå•ç¬¬ä¸€å€‹å…ƒç´ é©—è­‰çµæœï¼Œé¿å…np.sumé–‹éŠ·
            first_result = buf_result['host_ptr'][0]  
            times['result_access'].append(time.perf_counter() - start)
            
            # Cleanup
            start = time.perf_counter()
            self.return_buffer(buf_a)
            self.return_buffer(buf_b) 
            self.return_buffer(buf_result)
            times['cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“šï¼Œå»é™¤é¦–æ¬¡ç•°å¸¸å€¼
        def clean_mean(time_list):
            if len(time_list) > 5:
                # å»é™¤æœ€é«˜å’Œæœ€ä½å€¼ï¼Œé¿å…ç•°å¸¸å½±éŸ¿
                sorted_times = sorted(time_list[1:])  # è·³éé¦–æ¬¡
                return np.mean(sorted_times[1:-1]) if len(sorted_times) > 2 else np.mean(sorted_times)
            return np.mean(time_list)
        
        # è½‰æ›ç‚ºå¾®ç§’ä¸¦è¨ˆç®—å„ªåŒ–å¾Œçš„å¹³å‡å€¼
        metrics = PerformanceMetrics(
            setup_time_us=clean_mean(times['setup']) * 1_000_000,
            data_prep_time_us=clean_mean(times['data_prep']) * 1_000_000,
            kernel_time_us=clean_mean(times['kernel']) * 1_000_000,
            result_access_time_us=clean_mean(times['result_access']) * 1_000_000,
            cleanup_time_us=clean_mean(times['cleanup']) * 1_000_000,
            total_time_us=clean_mean(times['total']) * 1_000_000,
            memory_strategy=MemoryStrategy.USE_HOST_PTR,
            data_size=data_size
        )
        
        return metrics
        
    def _test_map_buffer_strategy(self, program, data_size: int, iterations: int) -> PerformanceMetrics:
        """æ¸¬è©¦å…§å­˜æ˜ å°„ç­–ç•¥"""
        kernel = program.memory_bandwidth_test
        
        times = {'setup': [], 'data_prep': [], 'kernel': [], 'result_access': [], 'cleanup': [], 'total': []}
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # Setup - å‰µå»ºå¯æ˜ å°„çš„buffer
            start = time.perf_counter()
            cl_input = cl.Buffer(self.context, cl.mem_flags.READ_WRITE | cl.mem_flags.ALLOC_HOST_PTR, size=data_size*4)
            cl_output = cl.Buffer(self.context, cl.mem_flags.READ_WRITE | cl.mem_flags.ALLOC_HOST_PTR, size=data_size*4)
            times['setup'].append(time.perf_counter() - start)
            
            # Data prep - æ˜ å°„ä¸¦å¯«å…¥
            start = time.perf_counter()
            mapped_input, event = cl.enqueue_map_buffer(
                self.queue, cl_input, cl.map_flags.WRITE, 0, (data_size,), np.float32
            )
            mapped_input.fill(3.14)  # é¿å…éš¨æ©Ÿæ•¸é–‹éŠ·
            event.wait()  # ç­‰å¾…æ˜ å°„å®Œæˆ
            times['data_prep'].append(time.perf_counter() - start)
            
            # Kernel execution
            start = time.perf_counter()
            kernel.set_arg(0, cl_input)
            kernel.set_arg(1, cl_output)
            kernel.set_arg(2, np.int32(data_size))
            
            event = cl.enqueue_nd_range_kernel(self.queue, kernel, (min(data_size, 1024),), None)
            event.wait()
            times['kernel'].append(time.perf_counter() - start)
            
            # Result access - æ˜ å°„ä¸¦è®€å–
            start = time.perf_counter()
            mapped_output, event = cl.enqueue_map_buffer(
                self.queue, cl_output, cl.map_flags.READ, 0, (data_size,), np.float32
            )
            event.wait()  # ç­‰å¾…æ˜ å°„å®Œæˆ
            result_sum = np.sum(mapped_output)
            times['result_access'].append(time.perf_counter() - start)
            
            # Cleanup
            start = time.perf_counter()
            # OpenCL buffersæœƒè‡ªå‹•é‡‹æ”¾
            times['cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        metrics = PerformanceMetrics(
            setup_time_us=np.mean(times['setup']) * 1_000_000,
            data_prep_time_us=np.mean(times['data_prep']) * 1_000_000,
            kernel_time_us=np.mean(times['kernel']) * 1_000_000,
            result_access_time_us=np.mean(times['result_access']) * 1_000_000,
            cleanup_time_us=np.mean(times['cleanup']) * 1_000_000,
            total_time_us=np.mean(times['total']) * 1_000_000,
            memory_strategy=MemoryStrategy.MAP_BUFFER,
            data_size=data_size
        )
        
        return metrics
        
    def _test_traditional_strategy(self, program, data_size: int, iterations: int) -> PerformanceMetrics:
        """æ¸¬è©¦å‚³çµ±bufferç­–ç•¥ï¼ˆå°æ¯”åŸºæº–ï¼‰"""
        kernel = program.advanced_vector_add
        
        times = {'setup': [], 'data_prep': [], 'kernel': [], 'result_access': [], 'cleanup': [], 'total': []}
        
        for i in range(iterations):
            start_total = time.perf_counter()
            
            # Setup
            start = time.perf_counter()
            host_a = np.full(data_size, 1.5, dtype=np.float32)
            host_b = np.full(data_size, 2.5, dtype=np.float32)
            host_result = np.empty(data_size, dtype=np.float32)
            
            cl_a = cl.Buffer(self.context, cl.mem_flags.READ_ONLY, host_a.nbytes)
            cl_b = cl.Buffer(self.context, cl.mem_flags.READ_ONLY, host_b.nbytes)
            cl_result = cl.Buffer(self.context, cl.mem_flags.WRITE_ONLY, host_result.nbytes)
            times['setup'].append(time.perf_counter() - start)
            
            # Data prep - éœ€è¦æ‹·è²åˆ°GPU
            start = time.perf_counter()
            cl.enqueue_copy(self.queue, cl_a, host_a).wait()
            cl.enqueue_copy(self.queue, cl_b, host_b).wait()
            times['data_prep'].append(time.perf_counter() - start)
            
            # Kernel execution
            start = time.perf_counter()
            kernel.set_arg(0, cl_a)
            kernel.set_arg(1, cl_b)
            kernel.set_arg(2, cl_result)
            kernel.set_arg(3, np.int32(data_size))
            
            event = cl.enqueue_nd_range_kernel(self.queue, kernel, (min(data_size, 1024),), None)
            event.wait()
            times['kernel'].append(time.perf_counter() - start)
            
            # Result access - éœ€è¦å¾GPUæ‹·è²å›ä¾†
            start = time.perf_counter()
            cl.enqueue_copy(self.queue, host_result, cl_result).wait()
            result_sum = np.sum(host_result)
            times['result_access'].append(time.perf_counter() - start)
            
            # Cleanup
            start = time.perf_counter()
            # buffersè‡ªå‹•é‡‹æ”¾
            times['cleanup'].append(time.perf_counter() - start)
            
            times['total'].append(time.perf_counter() - start_total)
        
        metrics = PerformanceMetrics(
            setup_time_us=np.mean(times['setup']) * 1_000_000,
            data_prep_time_us=np.mean(times['data_prep']) * 1_000_000,
            kernel_time_us=np.mean(times['kernel']) * 1_000_000,
            result_access_time_us=np.mean(times['result_access']) * 1_000_000,
            cleanup_time_us=np.mean(times['cleanup']) * 1_000_000,
            total_time_us=np.mean(times['total']) * 1_000_000,
            memory_strategy=MemoryStrategy.TRADITIONAL_BUFFER,
            data_size=data_size
        )
        
        return metrics
        
    def run_comprehensive_benchmark(self):
        """é‹è¡Œå…¨é¢çš„æ€§èƒ½å°æ¯”"""
        logger.info("ğŸ¯ é–‹å§‹å…¨é¢é›¶æ‹·è²æŠ€è¡“å°æ¯”æ¸¬è©¦")
        
        # æ¸¬è©¦ç­–ç•¥ - åŒ…å«äºæ¯«ç§’ç´šå„ªåŒ–
        strategies = [
            MemoryStrategy.TRADITIONAL_BUFFER, 
            MemoryStrategy.USE_HOST_PTR, 
            MemoryStrategy.ULTRA_FAST_HOST_PTR,
            MemoryStrategy.MAP_BUFFER,
            MemoryStrategy.SVM_COARSE  # SVMå¿…å®šå¯ç”¨
        ]
            
        test_sizes = [1024, 10240, 102400, 1024000]
        
        results = {}
        
        logger.info(f"\nğŸ“Š æ¸¬è©¦ç­–ç•¥: {[s.value for s in strategies]}")
        logger.info(f"ğŸ“Š æ¸¬è©¦å¤§å°: {test_sizes}")
        logger.info("ğŸš€ RetryIX SVM æ¸¬è©¦å·²å•Ÿç”¨")
        
        for strategy in strategies:
            logger.info(f"\nğŸ”¬ æ¸¬è©¦ç­–ç•¥: {strategy.value}")
            results[strategy] = {}
            
            for size in test_sizes:
                logger.info(f"   æ¸¬è©¦å¤§å°: {size} å…ƒç´  ({size*4/1024:.1f} KB)")
                
                # æ¨™æº–è¿­ä»£æ¬¡æ•¸
                iterations = 10
                
                metrics = self.test_memory_strategy(strategy, size, iterations=iterations)
                results[strategy][size] = metrics
                
                # ç‰¹åˆ¥æ¨™è¨»äºæ¯«ç§’ç´šæ€§èƒ½
                if metrics.total_time_us < 1000:  # å°æ–¼1æ¯«ç§’
                    logger.info(f"     ç¸½æ™‚é–“: {metrics.total_time_us:.1f} Î¼s âš¡ äºæ¯«ç§’ç´š!")
                else:
                    logger.info(f"     ç¸½æ™‚é–“: {metrics.total_time_us:.1f} Î¼s ({metrics.total_time_us/1000:.2f} ms)")
                    
                logger.info(f"     å…¶ä¸­å…§æ ¸: {metrics.kernel_time_us:.1f} Î¼s ({metrics.kernel_time_us/metrics.total_time_us*100:.1f}%)")
                
                # å¯¦æ™‚é¡¯ç¤ºæ•¸æ“šæº–å‚™æ•ˆç‡
                if metrics.data_prep_time_us < 100:  # å°æ–¼0.1æ¯«ç§’
                    logger.info(f"     æ•¸æ“šæº–å‚™: {metrics.data_prep_time_us:.1f} Î¼s âš¡ è¶…é«˜æ•ˆ!")
        
        self._analyze_comprehensive_results(results)
        return results
        
    def _analyze_comprehensive_results(self, results: Dict):
        """åˆ†æç¶œåˆæ¸¬è©¦çµæœ"""
        logger.info("\n" + "="*80)
        logger.info("ğŸ¯ é«˜ç´šé›¶æ‹·è²æŠ€è¡“æ•ˆæœåˆ†æ")
        logger.info("="*80)
        
        strategies = list(results.keys())
        test_sizes = list(results[strategies[0]].keys())
        
        # å‰µå»ºæ€§èƒ½å°æ¯”è¡¨
        logger.info(f"\nğŸ“Š æ€§èƒ½å°æ¯”è¡¨ (æ™‚é–“å–®ä½: å¾®ç§’)")
        
        header = "ç­–ç•¥\\å¤§å°".ljust(20)
        for size in test_sizes:
            header += f"{size}({size*4//1024}KB)".rjust(15)
        logger.info(header)
        logger.info("-" * len(header))
        
        baseline_results = results.get(MemoryStrategy.TRADITIONAL_BUFFER, {})
        
        for strategy in strategies:
            strategy_results = results[strategy]
            row = strategy.value.ljust(20)
            
            for size in test_sizes:
                metrics = strategy_results[size]
                time_us = metrics.total_time_us
                
                # å¦‚æœæœ‰åŸºæº–æ¸¬è©¦ï¼Œè¨ˆç®—åŠ é€Ÿæ¯”
                if baseline_results and size in baseline_results:
                    baseline_time = baseline_results[size].total_time_us
                    speedup = baseline_time / time_us
                    row += f"{time_us:.0f}({speedup:.2f}x)".rjust(15)
                else:
                    row += f"{time_us:.0f}Î¼s".rjust(15)
            
            logger.info(row)
        
        # åˆ†ææœ€ä½³ç­–ç•¥
        logger.info(f"\nğŸ† æœ€ä½³ç­–ç•¥åˆ†æ:")
        
        for size in test_sizes:
            best_strategy = min(strategies, key=lambda s: results[s][size].total_time_us)
            best_metrics = results[best_strategy][size]
            
            logger.info(f"\n   æ•¸æ“šå¤§å° {size} ({size*4/1024:.1f} KB):")
            logger.info(f"     æœ€ä½³ç­–ç•¥: {best_strategy.value}")
            logger.info(f"     ç¸½æ™‚é–“: {best_metrics.total_time_us:.1f} Î¼s")
            logger.info(f"     è¨ˆç®—å æ¯”: {best_metrics.kernel_time_us/best_metrics.total_time_us*100:.1f}%")
            
            # èˆ‡å‚³çµ±æ–¹æ³•å°æ¯”
            if MemoryStrategy.TRADITIONAL_BUFFER in results:
                traditional = results[MemoryStrategy.TRADITIONAL_BUFFER][size]
                improvement = traditional.total_time_us / best_metrics.total_time_us
                logger.info(f"     æ€§èƒ½æå‡: {improvement:.2f}å€")
        
        # æŠ€è¡“çªç ´ç¸½çµ - å°ˆæ³¨äºæ¯«ç§’ç´šæˆæœ
        logger.info(f"\nğŸš€ äºæ¯«ç§’ç´šæŠ€è¡“çªç ´ç¸½çµ:")
        
        # çµ±è¨ˆäºæ¯«ç§’ç´šæ€§èƒ½
        submillisecond_count = 0
        total_tests = 0
        
        for strategy in strategies:
            for size in test_sizes:
                metrics = results[strategy][size]
                total_tests += 1
                if metrics.total_time_us < 1000:  # äºæ¯«ç§’ç´š
                    submillisecond_count += 1
        
        logger.info(f"ğŸ“ˆ äºæ¯«ç§’ç´šæ¸¬è©¦å æ¯”: {submillisecond_count}/{total_tests} ({submillisecond_count/total_tests*100:.1f}%)")
        
        # æ‰¾å‡ºæœ€å¿«çš„å¯¦ç¾
        fastest_overall = float('inf')
        fastest_strategy = None
        fastest_size = None
        
        for strategy in strategies:
            for size in test_sizes:
                metrics = results[strategy][size]
                if metrics.total_time_us < fastest_overall:
                    fastest_overall = metrics.total_time_us
                    fastest_strategy = strategy
                    fastest_size = size
        
        logger.info(f"âš¡ æœ€å¿«è¨˜éŒ„: {fastest_strategy.value} @ {fastest_size}å…ƒç´  = {fastest_overall:.1f} Î¼s")
        
        # è¨ˆç®—å¹³å‡è¨ˆç®—å æ¯”æå‡
        compute_ratios = {}
        for strategy in strategies:
            ratios = []
            for size in test_sizes:
                metrics = results[strategy][size]
                ratio = metrics.kernel_time_us / metrics.total_time_us
                ratios.append(ratio)
            compute_ratios[strategy] = np.mean(ratios)
        
        best_compute_strategy = max(compute_ratios.keys(), key=lambda s: compute_ratios[s])
        
        logger.info(f"âœ… æœ€é«˜è¨ˆç®—å æ¯”ç­–ç•¥: {best_compute_strategy.value} ({compute_ratios[best_compute_strategy]*100:.1f}%)")
        
        # äºæ¯«ç§’ç´šçªç ´åˆ¤æ–·
        best_submillisecond_strategy = None
        for strategy in strategies:
            avg_time = np.mean([results[strategy][size].total_time_us for size in test_sizes[:2]])  # å°æ•¸æ“š
            if avg_time < 1000:  # å¹³å‡äºæ¯«ç§’ç´š
                best_submillisecond_strategy = strategy
                break
        
        if best_submillisecond_strategy:
            logger.info("ğŸ‰ äºæ¯«ç§’ç´šçªç ´æˆåŠŸï¼æ•¸æ“šå‚³è¼¸å»¶é²åŸºæœ¬æ¶ˆé™¤")
        elif compute_ratios[best_compute_strategy] > 0.7:
            logger.info("ğŸ‰ çªç ´æˆåŠŸï¼è¨ˆç®—æˆç‚ºä¸»å°ï¼Œå…§å­˜ç“¶é ¸åŸºæœ¬æ¶ˆé™¤")
        elif compute_ratios[best_compute_strategy] > 0.5:
            logger.info("ğŸ”¥ é¡¯è‘—æ”¹å–„ï¼å…§å­˜ç“¶é ¸å¤§å¹…é™ä½")
        else:
            logger.info("âš¡ ä»æœ‰æå‡ç©ºé–“ï¼Œå»ºè­°é€²ä¸€æ­¥å„ªåŒ–")
            
        # æ¨è–¦æ–¹æ¡ˆ - çªå‡ºäºæ¯«ç§’ç´šæ€§èƒ½
        logger.info(f"\nğŸ’¡ æ€§èƒ½æ¨è–¦æ–¹æ¡ˆ:")
        
        def find_best_for_size(target_size):
            candidates = []
            for strategy in strategies:
                metrics = results[strategy][target_size]
                candidates.append((strategy, metrics.total_time_us, metrics.kernel_time_us/metrics.total_time_us))
            
            # å„ªå…ˆé¸æ“‡äºæ¯«ç§’ç´šï¼Œç„¶å¾Œæ˜¯è¨ˆç®—å æ¯”é«˜çš„
            candidates.sort(key=lambda x: (x[1] >= 1000, x[1], -x[2]))
            return candidates[0] if candidates else None
        
        for size, desc in [(1024, "å°æ•¸æ“š(< 10KB)"), (10240, "ä¸­æ•¸æ“š(10KB-100KB)"), (102400, "å¤§æ•¸æ“š(100KB-1MB)"), (1024000, "è¶…å¤§æ•¸æ“š(> 1MB)")]:
            best = find_best_for_size(size)
            if best:
                strategy, time_us, compute_ratio = best
                time_desc = f"{time_us:.0f}Î¼s âš¡" if time_us < 1000 else f"{time_us/1000:.2f}ms"
                logger.info(f"   {desc}: {strategy.value} ({time_desc}, è¨ˆç®—å æ¯”{compute_ratio*100:.1f}%)")

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    advanced_zc = AdvancedZeroCopy()
    
    # åˆå§‹åŒ– - ä»»ä½•å¤±æ•—éƒ½ç›´æ¥å ±éŒ¯
    advanced_zc.initialize_opencl()
    
    # é‹è¡Œå…¨é¢æ¸¬è©¦ - ä»»ä½•å¤±æ•—éƒ½ç›´æ¥å ±éŒ¯
    results = advanced_zc.run_comprehensive_benchmark()
    
    logger.info("\nğŸ‰ é«˜ç´šé›¶æ‹·è²æŠ€è¡“æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    main()